{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ü©∫ Skin Disease Classification: Exploration & Training\n",
    "\n",
    "This notebook explores the `skin-ga5ww` dataset from Roboflow and trains a **YOLO11** classification model using the Ultralytics framework.\n",
    "\n",
    "**Objectives:**\n",
    "1.  **Explore:** Visualize images, count samples, identify classes, check splits, and analyze class imbalance.\n",
    "2.  **Train:** Train a YOLO11-cls model on the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Installation\n",
    "Install the necessary libraries: `roboflow` for dataset management and `ultralytics` for the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install roboflow ultralytics matplotlib seaborn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Download Data from Roboflow\n",
    "We will download the dataset using the Roboflow API. \n",
    "\n",
    "**‚ö†Ô∏è IMPORTANT:** You must replace `\"INSERT_ROBOFLOW_API_KEY_HERE\"` with your actual Private API Key from your Roboflow settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from roboflow import Roboflow\n",
    "import os\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "API_KEY = \"INSERT_ROBOFLOW_API_KEY_HERE\" # ‚ö†Ô∏è PASTE YOUR KEY HERE\n",
    "WORKSPACE = \"cxrdataset\"\n",
    "PROJECT = \"skin-ga5ww\"\n",
    "VERSION = 1 # We assume version 1, change if you are using a specific version\n",
    "# ---------------------\n",
    "\n",
    "try:\n",
    "    rf = Roboflow(api_key=API_KEY)\n",
    "    project = rf.workspace(WORKSPACE).project(PROJECT)\n",
    "    dataset = project.version(VERSION).download(\"folder\")\n",
    "    dataset_path = dataset.location\n",
    "    print(f\"\\n‚úÖ Dataset downloaded to: {dataset_path}\")\n",
    "except Exception as e:\n",
    "    print(\"\\n‚ùå Error downloading dataset. Please check your API Key and Project permissions.\")\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Dataset Exploration & Analysis\n",
    "Here we write a custom script to walk through the folders, count the images, and analyze the distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import random\n",
    "\n",
    "def explore_dataset(root_path):\n",
    "    splits = ['train', 'valid', 'test']\n",
    "    data_stats = []\n",
    "\n",
    "    # 1. Parse Directory Structure\n",
    "    print(f\"Analyzing dataset at: {root_path}...\")\n",
    "    \n",
    "    for split in splits:\n",
    "        split_path = os.path.join(root_path, split)\n",
    "        if not os.path.exists(split_path):\n",
    "            print(f\"‚ö†Ô∏è Split '{split}' not found (Roboflow sometimes names valid as 'valid' or 'val')\")\n",
    "            # Try alternative name for validation\n",
    "            if split == 'valid':\n",
    "                split_path = os.path.join(root_path, 'val')\n",
    "                if os.path.exists(split_path): \n",
    "                    split = 'val'\n",
    "                else:\n",
    "                    continue\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "        # Get classes (subfolders)\n",
    "        classes = [d for d in os.listdir(split_path) if os.path.isdir(os.path.join(split_path, d))]\n",
    "        \n",
    "        for cls in classes:\n",
    "            class_path = os.path.join(split_path, cls)\n",
    "            num_images = len(glob.glob(os.path.join(class_path, '*.*')))\n",
    "            data_stats.append({'Split': split, 'Class': cls, 'Count': num_images})\n",
    "\n",
    "    df = pd.DataFrame(data_stats)\n",
    "    \n",
    "    # 2. Display Statistics\n",
    "    if df.empty:\n",
    "        print(\"‚ùå No data found. Check the dataset path.\")\n",
    "        return\n",
    "        \n",
    "    print(\"\\nüìä Dataset Statistics:\")\n",
    "    total_images = df['Count'].sum()\n",
    "    print(f\"Total Images: {total_images}\")\n",
    "    print(f\"Classes Detected: {df['Class'].unique()}\")\n",
    "    print(\"\\nBreakdown by Split and Class:\")\n",
    "    print(df.pivot(index='Class', columns='Split', values='Count').fillna(0))\n",
    "\n",
    "    # 3. Check for Imbalance\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.barplot(data=df, x='Class', y='Count', hue='Split')\n",
    "    plt.title('Class Distribution across Splits')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.show()\n",
    "\n",
    "    # 4. Visualize Samples\n",
    "    print(\"\\nüñºÔ∏è Sample Images (One per class from Train split):\")\n",
    "    train_split = 'train'\n",
    "    classes = df[df['Split'] == train_split]['Class'].unique()\n",
    "    \n",
    "    fig, axes = plt.subplots(1, len(classes), figsize=(15, 5))\n",
    "    if len(classes) == 1: axes = [axes]\n",
    "    \n",
    "    for i, cls in enumerate(classes):\n",
    "        cls_path = os.path.join(root_path, train_split, cls)\n",
    "        images = glob.glob(os.path.join(cls_path, '*.*'))\n",
    "        if images:\n",
    "            img_path = random.choice(images)\n",
    "            img = Image.open(img_path)\n",
    "            axes[i].imshow(img)\n",
    "            axes[i].set_title(cls)\n",
    "            axes[i].axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# Run exploration\n",
    "if 'dataset_path' in locals():\n",
    "    explore_dataset(dataset_path)\n",
    "else:\n",
    "    print(\"Please download the dataset first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Train YOLO11 Model\n",
    "We will now train a **YOLO11** (Nano) model for image classification. YOLO11 is the latest state-of-the-art model from Ultralytics.\n",
    "\n",
    "**Settings:**\n",
    "- **Model:** `yolo11n-cls.pt` (Nano version, pretrained on ImageNet, fastest training)\n",
    "- **Epochs:** `20` (Adjust based on your needs)\n",
    "- **Image Size:** `224` (Standard for classification)\n",
    "- **Device:** `0` (Uses the Colab GPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Initialize YOLO11 classifier\n",
    "# 'n' stands for nano (smallest/fastest). You can also use yolo11s-cls.pt (small), yolo11m-cls.pt (medium)\n",
    "model = YOLO('yolo11n-cls.pt') \n",
    "\n",
    "# Train the model\n",
    "# We point 'data' to the dataset folder downloaded by Roboflow\n",
    "results = model.train(\n",
    "    data=dataset_path, \n",
    "    epochs=20, \n",
    "    imgsz=224, \n",
    "    project=\"skin_disease_project\",\n",
    "    name=\"yolo11n_skin_cls\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Validate and Inference\n",
    "Check the accuracy on the validation/test set and run a prediction on a random test image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate on the test/val set automatically included in the dataset folder\n",
    "metrics = model.val()\n",
    "print(f\"Top-1 Accuracy: {metrics.top1}\")\n",
    "print(f\"Top-5 Accuracy: {metrics.top5}\")\n",
    "\n",
    "# Run Inference on a random image from the test set\n",
    "import glob\n",
    "import random\n",
    "\n",
    "test_images = glob.glob(f\"{dataset_path}/test/*/*.*\")\n",
    "if test_images:\n",
    "    test_image = random.choice(test_images)\n",
    "    \n",
    "    # Predict\n",
    "    results = model.predict(test_image)\n",
    "    \n",
    "    # Show results\n",
    "    for result in results:\n",
    "        result.show()  # Display the image with class label\n",
    "        print(f\"Prediction: {result.names[result.probs.top1]} ({result.probs.top1conf:.2f})\")\n",
    "else:\n",
    "    print(\"No test images found.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
